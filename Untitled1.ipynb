{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdd68201",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43be8006",
   "metadata": {},
   "source": [
    "Classification Testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ba2b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9417c4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /home/devilunraveled/.pyenv/versions/3.12.2/envs/wordvectorization/lib/python3.12/site-packages (3.8.1)\n",
      "Requirement already satisfied: click in /home/devilunraveled/.pyenv/versions/3.12.2/envs/wordvectorization/lib/python3.12/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /home/devilunraveled/.pyenv/versions/3.12.2/envs/wordvectorization/lib/python3.12/site-packages (from nltk) (1.4.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/devilunraveled/.pyenv/versions/3.12.2/envs/wordvectorization/lib/python3.12/site-packages (from nltk) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in /home/devilunraveled/.pyenv/versions/3.12.2/envs/wordvectorization/lib/python3.12/site-packages (from nltk) (4.66.2)\n"
     ]
    }
   ],
   "source": [
    "# custom installation for notebook.\n",
    "!pip3.12 install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6ed83be",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclassification\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RNNClassifier\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparser\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mConfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SVDConfig\n",
      "File \u001b[0;32m~/College/Sem6/IntroToNLP/Assignments/WordVectorization/src/parser.py:4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfunctools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cache\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Optional\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtokenize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m word_tokenize \u001b[38;5;28;01mas\u001b[39;00m Tokenizer\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbidict\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m bidict\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "from src.classification import RNNClassifier\n",
    "from src.parser import Dataset\n",
    "from src.Config import SVDConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3050e8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(fileName = \"model.pkl\", svdLoad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634ba78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.getData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffaebb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run only if SVD Embeddings are not precomputed.\n",
    "dataset.setSVDEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ccc805",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.getTestData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748f5285",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = [ (label, tuple(tokenizedSentence)) for label, tokenizedSentence in zip(dataset.labels, dataset.tokenizedData)]\n",
    "testData = [ (label, tuple(tokenizedSentence)) for label, tokenizedSentence in zip(dataset.testLabels, dataset.testData)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c5a742",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData[0][1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70434f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.getSVDEmbedding(trainData[0][1][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f529f02",
   "metadata": {},
   "source": [
    "### Using SVD Embeddings for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e11769",
   "metadata": {},
   "outputs": [],
   "source": [
    "svdBasedClassifier = RNNClassifier(inputSize=256, embeddingMap=dataset.getSVDEmbedding, \n",
    "                                   data=trainData, testData=testData, \n",
    "                                   fileName = f\"svdClassifier_{SVDConfig.contextWindow}.pt\")\n",
    "svdBasedClassifier.createDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8187587",
   "metadata": {},
   "outputs": [],
   "source": [
    "svdBasedClassifier.trainModel()\n",
    "# svdBasedClassifier.loadModel(fileName = svdBasedClassifier.fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf665fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "svdBasedClassifier.evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f54a2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "svdBasedClassifier.plotConfusionMatrix(name=f\"SVD_{SVDConfig.EmbeddingSize}_{SVDConfig.contextWindow}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuralPosTagging",
   "language": "python",
   "name": "neuralpostagging"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
